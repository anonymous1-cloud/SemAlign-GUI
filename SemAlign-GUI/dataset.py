#!/usr/bin/env python3
"""
GUIæ•°æ®å®Œæ•´é¢„å¤„ç†å·¥å…· - ä¿®å¤ç‰ˆ
ä¿®å¤ç»„ä»¶åæ ‡ç¼©æ”¾é—®é¢˜ï¼Œç¡®ä¿ä¸224Ã—224å›¾åƒå¯¹é½
"""
import gc
import json
import random
import re
import sys
from argparse import ArgumentParser
from pathlib import Path

import cv2
import h5py
import numpy as np
import torch
import ijson
from sklearn.model_selection import train_test_split
from tqdm import tqdm

sys.path.append('.')
try:
    from config3 import get_full_config
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥é…ç½®: {e}")
    sys.exit(1)

# ---------- é¢œè‰²æ˜ å°„ ----------
COLOR_MAPPING = {
    (0, 255, 0): ("TextView", 1.2), (0, 0, 255): ("ImageView", 1.5),
    (198, 204, 79): ("CheckedTextView", 1.0), (93, 47, 207): ("WebView", 1.5),
    (187, 187, 187): ("View", 0.8), (255, 0, 0): ("EditText", 1.5),
    (238, 179, 142): ("ToggleButton", 1.0), (150, 105, 72): ("ToggleButtonOutline", 0.7),
    (0, 165, 255): ("RadioButton", 1.1), (0, 255, 255): ("Button", 1.3),
    (15, 196, 241): ("CheckBox", 1.0), (139, 125, 96): ("SwitchMain", 1.0),
    (56, 234, 251): ("SwitchSlider", 1.0), (203, 192, 255): ("Widget", 0.8)
}

# ---------- GPU åŠ é€Ÿ ----------
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


@torch.inference_mode()
def gpu_image_pipeline(image_path, target_size, dtype=torch.float16):
    """åŠ è½½ã€ç¼©æ”¾å’Œæ ‡å‡†åŒ–å›¾åƒ"""
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    tensor = torch.from_numpy(img).to(DEVICE, dtype=dtype).permute(2, 0, 1)
    del img
    tensor = torch.nn.functional.interpolate(
        tensor.unsqueeze(0), size=target_size, mode='bilinear', align_corners=False
    ).squeeze(0)
    mean = torch.tensor([0.485, 0.456, 0.406], device=DEVICE, dtype=dtype).view(3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225], device=DEVICE, dtype=dtype).view(3, 1, 1)
    return ((tensor / 255. - mean) / std).contiguous()


# ---------- ä¿®å¤ï¼šç»„ä»¶æ£€æµ‹ï¼ˆåŒæ­¥ç¼©æ”¾ï¼‰ ----------
class FixedColorComponentDetector:
    def __init__(self, color_mapping=COLOR_MAPPING, tolerance=10):  # å‡å°å®¹å·®
        self.color_mapping = color_mapping
        self.tolerance = tolerance

    def detect_components(self, image_path, target_size=(224, 224)):
        """æ£€æµ‹ç»„ä»¶å¹¶ç›´æ¥è¿”å›ç¼©æ”¾åçš„åæ ‡"""
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")

        original_h, original_w = image.shape[:2]
        target_w, target_h = target_size

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale_x = target_w / original_w
        scale_y = target_h / original_h

        components = []
        for color, (comp_type, weight) in self.color_mapping.items():
            lower = np.array([max(0, c - self.tolerance) for c in color])
            upper = np.array([min(255, c + self.tolerance) for c in color])

            mask = cv2.inRange(image, lower, upper)

            # å½¢æ€å­¦å¤„ç†ï¼ˆå‡å°‘å™ªå£°ï¼‰
            kernel = np.ones((2, 2), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            for cnt in contours:
                area = cv2.contourArea(cnt)
                if area > 10:  # å‡å°é¢ç§¯é˜ˆå€¼
                    x, y, ww, hh = cv2.boundingRect(cnt)

                    # === å…³é”®ä¿®å¤ï¼šç«‹å³ç¼©æ”¾åæ ‡ ===
                    scaled_x1 = int(x * scale_x)
                    scaled_y1 = int(y * scale_y)
                    scaled_x2 = int((x + ww) * scale_x)
                    scaled_y2 = int((y + hh) * scale_y)

                    # ç¡®ä¿åæ ‡åœ¨ç›®æ ‡å›¾åƒèŒƒå›´å†…
                    scaled_x1 = max(0, min(scaled_x1, target_w - 1))
                    scaled_y1 = max(0, min(scaled_y1, target_h - 1))
                    scaled_x2 = max(1, min(scaled_x2, target_w))
                    scaled_y2 = max(1, min(scaled_y2, target_h))

                    # ç¡®ä¿è¾¹ç•Œæ¡†æœ‰æ•ˆ
                    if scaled_x2 <= scaled_x1 or scaled_y2 <= scaled_y1:
                        continue

                    # è®¡ç®—ç¼©æ”¾åçš„é¢ç§¯
                    scaled_area = (scaled_x2 - scaled_x1) * (scaled_y2 - scaled_y1)
                    if scaled_area < 4:  # è·³è¿‡å¤ªå°çš„ç»„ä»¶
                        continue

                    components.append({
                        'type': comp_type,
                        'bbox': [scaled_x1, scaled_y1, scaled_x2, scaled_y2],  # 224Ã—224åæ ‡
                        'weight': weight,
                        'area': scaled_area
                    })

        # æŒ‰é¢ç§¯æ’åºå¹¶é™åˆ¶æ•°é‡
        components.sort(key=lambda x: x['area'], reverse=True)
        return components[:20]

    def validate_components(self, components, image_size=(224, 224)):
        """éªŒè¯ç»„ä»¶åæ ‡æ˜¯å¦æœ‰æ•ˆ"""
        img_w, img_h = image_size
        valid_components = []

        for comp in components:
            bbox = comp.get('bbox', [])
            if len(bbox) != 4:
                continue

            x1, y1, x2, y2 = bbox

            # æ£€æŸ¥è¾¹ç•Œ
            if (0 <= x1 < x2 <= img_w) and (0 <= y1 < y2 <= img_h):
                valid_components.append(comp)
            else:
                # ä¿®å¤è¾¹ç•Œé—®é¢˜
                fixed_bbox = [
                    max(0, min(x1, img_w - 1)),
                    max(0, min(y1, img_h - 1)),
                    max(1, min(x2, img_w)),
                    max(1, min(y2, img_h))
                ]
                if fixed_bbox[0] < fixed_bbox[2] and fixed_bbox[1] < fixed_bbox[3]:
                    comp['bbox'] = fixed_bbox
                    valid_components.append(comp)

        return valid_components


# ---------- ä¿®å¤ï¼šåæ ‡å¤„ç†å™¨ ----------
class FixedCoordinateProcessor:
    def __init__(self, original_size=(144, 256), target_size=(224, 224)):
        self.original_size = original_size
        self.target_size = target_size

    def scale_bbox(self, bbox):
        """ç¼©æ”¾bboxä»åŸå§‹å°ºå¯¸åˆ°ç›®æ ‡å°ºå¯¸"""
        if len(bbox) != 4:
            return [0, 0, 0, 0]

        orig_w, orig_h = self.original_size
        target_w, target_h = self.target_size

        x1, y1, x2, y2 = bbox

        # ç¼©æ”¾
        scaled_x1 = int(x1 * target_w / orig_w)
        scaled_y1 = int(y1 * target_h / orig_h)
        scaled_x2 = int(x2 * target_w / orig_w)
        scaled_y2 = int(y2 * target_h / orig_h)

        # ç¡®ä¿åœ¨èŒƒå›´å†…
        scaled_x1 = max(0, min(scaled_x1, target_w - 1))
        scaled_y1 = max(0, min(scaled_y1, target_h - 1))
        scaled_x2 = max(1, min(scaled_x2, target_w))
        scaled_y2 = max(1, min(scaled_y2, target_h))

        return [scaled_x1, scaled_y1, scaled_x2, scaled_y2]

    def normalize_bbox(self, bbox):
        """å°†bboxå½’ä¸€åŒ–åˆ°[0,1]ï¼ˆç”¨äºchangeså­—æ®µï¼‰"""
        x1, y1, x2, y2 = bbox
        target_w, target_h = self.target_size
        return [x1 / target_w, y1 / target_h, x2 / target_w, y2 / target_h]

    def parse_difference_description(self, differ_str, max_changes=10):
        """è§£æå·®å¼‚æè¿°ï¼Œè¿”å›ç¼©æ”¾åçš„åæ ‡"""
        changes = {'moved': [], 'added': [], 'removed': [], 'unchanged': []}

        # è§£æAdded
        added_pattern = r'Added (\w+) at position \((\d+), (\d+), (\d+), (\d+)\)'
        for comp_type, x1, y1, x2, y2 in re.findall(added_pattern, differ_str):
            bbox = self.scale_bbox([int(x1), int(y1), int(x2), int(y2)])
            norm_bbox = self.normalize_bbox(bbox)
            changes['added'].append({'type': comp_type, 'bbox': norm_bbox})

        # è§£æRemoved
        removed_pattern = r'Removed (\w+) from position \((\d+), (\d+), (\d+), (\d+)\)'
        for comp_type, x1, y1, x2, y2 in re.findall(removed_pattern, differ_str):
            bbox = self.scale_bbox([int(x1), int(y1), int(x2), int(y2)])
            norm_bbox = self.normalize_bbox(bbox)
            changes['removed'].append({'type': comp_type, 'bbox': norm_bbox})

        # è§£æMoved
        moved_pattern = r'(\w+) from \((\d+), (\d+), (\d+), (\d+)\) to \((\d+), (\d+), (\d+), (\d+)\)'
        for comp_type, fx1, fy1, fx2, fy2, tx1, ty1, tx2, ty2 in re.findall(moved_pattern, differ_str):
            from_bbox = self.scale_bbox([int(fx1), int(fy1), int(fx2), int(fy2)])
            to_bbox = self.scale_bbox([int(tx1), int(ty1), int(tx2), int(ty2)])
            changes['moved'].append({
                'type': comp_type,
                'from_bbox': self.normalize_bbox(from_bbox),
                'to_bbox': self.normalize_bbox(to_bbox)
            })

        # é™åˆ¶æ•°é‡å¹¶æ’åº
        important = ['ImageView', 'Button', 'TextView', 'EditText', 'WebView']
        for t in ['moved', 'added', 'removed']:
            imp = [c for c in changes[t] if c['type'] in important]
            other = [c for c in changes[t] if c['type'] not in important]
            changes[t] = (imp + other)[:max_changes]

        return changes

    def truncate_description(self, differ_str, max_length=512):
        """æˆªæ–­æè¿°æ–‡æœ¬"""
        if len(differ_str) <= max_length:
            return differ_str
        changes = differ_str.split('; ')
        imp = [c for c in changes if any(k in c for k in ['ImageView', 'Button', 'TextView', 'EditText'])]
        other = [c for c in changes if c not in imp]
        truncated = '; '.join(imp + other)
        return truncated[:max_length - 3] + '...' if len(truncated) > max_length else truncated


# ---------- å˜åŒ– mask ç”Ÿæˆ ----------
def generate_change_mask(differ_str, target_size=(224, 224)):
    """ç”Ÿæˆå˜åŒ–maskï¼ˆä½¿ç”¨ç¼©æ”¾åçš„åæ ‡ï¼‰"""
    h, w = target_size
    mask = np.zeros((h, w), dtype=np.uint8)

    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆä»144Ã—256åˆ°224Ã—224ï¼‰
    scale_w = w / 144
    scale_h = h / 256

    # å¤„ç†Added
    for comp_type, x1, y1, x2, y2 in re.findall(r'Added (\w+) at position \((\d+), (\d+), (\d+), (\d+)\)', differ_str):
        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
        # ç¼©æ”¾åæ ‡
        sx1 = int(x1 * scale_w)
        sy1 = int(y1 * scale_h)
        sx2 = int(x2 * scale_w)
        sy2 = int(y2 * scale_h)
        # ç¡®ä¿åœ¨èŒƒå›´å†…
        sx1, sy1 = max(0, sx1), max(0, sy1)
        sx2, sy2 = min(w, sx2), min(h, sy2)
        if sx1 < sx2 and sy1 < sy2:
            mask[sy1:sy2, sx1:sx2] = 1

    # å¤„ç†Removed
    for comp_type, x1, y1, x2, y2 in re.findall(r'Removed (\w+) from position \((\d+), (\d+), (\d+), (\d+)\)',
                                                differ_str):
        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
        sx1 = int(x1 * scale_w)
        sy1 = int(y1 * scale_h)
        sx2 = int(x2 * scale_w)
        sy2 = int(y2 * scale_h)
        sx1, sy1 = max(0, sx1), max(0, sy1)
        sx2, sy2 = min(w, sx2), min(h, sy2)
        if sx1 < sx2 and sy1 < sy2:
            mask[sy1:sy2, sx1:sx2] = 1

    # å¤„ç†Movedï¼ˆç›®æ ‡ä½ç½®ï¼‰
    for comp_type, from_pos, to_pos in re.findall(r'(\w+) from \(([\d, ]+)\) to \(([\d, ]+)\)', differ_str):
        x1, y1, x2, y2 = map(int, to_pos.split(', '))
        sx1 = int(x1 * scale_w)
        sy1 = int(y1 * scale_h)
        sx2 = int(x2 * scale_w)
        sy2 = int(y2 * scale_h)
        sx1, sy1 = max(0, sx1), max(0, sy1)
        sx2, sy2 = min(w, sx2), min(h, sy2)
        if sx1 < sx2 and sy1 < sy2:
            mask[sy1:sy2, sx1:sx2] = 1

    return mask


# ---------- HDF5 å­˜å‚¨ ----------
class HDF5Storage:
    def __init__(self, output_dir):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.img_path = self.output_dir / "images.h5"
        self.mask_path = self.output_dir / "masks.h5"
        self._files = {}

    def _open(self, flag='a'):
        if 'img' not in self._files:
            self._files['img'] = h5py.File(self.img_path, flag)
            self._files['mask'] = h5py.File(self.mask_path, flag)
        return self._files['img'], self._files['mask']

    def append_single(self, class_name, ref_tensor, tar_tensor, mask):
        """å•æ¡è¿½åŠ åˆ°HDF5"""
        img_f, mask_f = self._open()

        # åˆ›å»ºç»„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if class_name not in img_f:
            img_grp = img_f.create_group(class_name)
            mask_grp = mask_f.create_group(class_name)

            img_grp.create_dataset('reference_images',
                                   shape=(0, 3, 224, 224),
                                   maxshape=(None, 3, 224, 224),
                                   dtype=np.float16,
                                   compression='gzip', compression_opts=4,
                                   chunks=(1, 3, 224, 224))
            img_grp.create_dataset('target_images',
                                   shape=(0, 3, 224, 224),
                                   maxshape=(None, 3, 224, 224),
                                   dtype=np.float16,
                                   compression='gzip', compression_opts=4,
                                   chunks=(1, 3, 224, 224))
            mask_grp.create_dataset('change_masks',
                                    shape=(0, 224, 224),
                                    maxshape=(None, 224, 224),
                                    dtype=np.uint8,
                                    compression='gzip', compression_opts=4,
                                    chunks=(1, 224, 224))

        # è·å–æ•°æ®é›†
        ref_dset = img_f[class_name]['reference_images']
        tar_dset = img_f[class_name]['target_images']
        mask_dset = mask_f[class_name]['change_masks']

        # æ‰©å±•å¹¶å†™å…¥
        old_size = ref_dset.shape[0]
        ref_dset.resize(old_size + 1, axis=0)
        tar_dset.resize(old_size + 1, axis=0)
        mask_dset.resize(old_size + 1, axis=0)

        ref_dset[old_size] = ref_tensor.cpu().numpy().astype(np.float16)
        tar_dset[old_size] = tar_tensor.cpu().numpy().astype(np.float16)
        mask_dset[old_size] = mask

        return old_size

    def close(self):
        for f in self._files.values():
            f.close()
        self._files.clear()


# ---------- é¢„å¤„ç†ä¸»ç±» ----------
class FixedGUIPreprocessor:
    def __init__(self, config):
        self.cfg = config
        self.detector = FixedColorComponentDetector()
        self.coord_proc = FixedCoordinateProcessor(
            original_size=config['data']['original_size'],
            target_size=config['data']['image_size']
        )
        self.target_size = config['data']['image_size']

    def process_single(self, sample, class_name):
        """å¤„ç†å•ä¸ªæ ·æœ¬"""
        try:
            # æ„å»ºè·¯å¾„
            ref_path = Path(self.cfg['data']['gui_dir']) / class_name / sample['reference']
            tar_path = Path(self.cfg['data']['gui_dir']) / class_name / sample['target']

            if not ref_path.exists() or not tar_path.exists():
                print(f"è·³è¿‡ï¼šæ–‡ä»¶ä¸å­˜åœ¨ - {ref_path} æˆ– {tar_path}")
                return None

            # === å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç›¸åŒçš„target_size ===
            target_size = self.target_size

            # 1. å¤„ç†å›¾åƒï¼ˆç¼©æ”¾å¹¶æ ‡å‡†åŒ–ï¼‰
            ref_tensor = gpu_image_pipeline(str(ref_path), target_size).cpu()
            tar_tensor = gpu_image_pipeline(str(tar_path), target_size).cpu()

            # 2. æ£€æµ‹ç»„ä»¶ï¼ˆè¿”å›ç¼©æ”¾åçš„åæ ‡ï¼‰
            ref_comp = self.detector.detect_components(str(ref_path), target_size=target_size)
            tar_comp = self.detector.detect_components(str(tar_path), target_size=target_size)

            # éªŒè¯ç»„ä»¶åæ ‡
            ref_comp = self.detector.validate_components(ref_comp, target_size)
            tar_comp = self.detector.validate_components(tar_comp, target_size)

            # 3. å¤„ç†æ–‡æœ¬å·®å¼‚
            differ_text = self.coord_proc.truncate_description(
                sample['differ'],
                self.cfg['data']['max_text_length']
            )

            # 4. è§£æå˜åŒ–ï¼ˆä½¿ç”¨ç¼©æ”¾åçš„åæ ‡ï¼‰
            changes = self.coord_proc.parse_difference_description(sample['differ'])

            # 5. ç”Ÿæˆå˜åŒ–maskï¼ˆä½¿ç”¨ç¼©æ”¾åçš„åæ ‡ï¼‰
            change_mask = generate_change_mask(sample['differ'], target_size=target_size)

            # 6. è¿”å›ç»“æœ
            return {
                'image_pair': (ref_tensor, tar_tensor),
                'mask': change_mask,
                'reference_components': ref_comp,
                'target_components': tar_comp,
                'differ_text': differ_text,
                'changes': changes,
                'class_name': class_name,
                'reference_path': str(ref_path),
                'target_path': str(tar_path)
            }

        except Exception as e:
            print(f"è·³è¿‡æ ·æœ¬ {sample.get('reference', 'unknown')}: {e}")
            return None

    def process_all_stream(self, debug=False, gc_every=500):
        """æµå¼å¤„ç†æ‰€æœ‰æ•°æ®"""
        text_dir = Path(self.cfg['data']['text_dir'])
        if not text_dir.exists():
            print(f"âŒ æ–‡æœ¬ç›®å½•ä¸å­˜åœ¨: {text_dir}")
            return []

        json_files = list(text_dir.glob('*.json'))
        if debug:
            json_files = json_files[:2]
            print(f"è°ƒè¯•æ¨¡å¼ï¼šåªå¤„ç†å‰{len(json_files)}ä¸ªç±»åˆ«")

        meta_dir = Path(self.cfg['data']['output_dir']) / 'meta'
        meta_dir.mkdir(exist_ok=True)

        all_meta_files = []

        for json_file in tqdm(json_files, desc="å¤„ç†JSONæ–‡ä»¶"):
            class_name = json_file.stem
            print(f"\nå¤„ç†ç±»åˆ«: {class_name}")

            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    samples = list(ijson.items(f, 'item'))

                if debug:
                    samples = samples[:50]
                    print(f"  è°ƒè¯•æ¨¡å¼ï¼šåªå¤„ç†å‰{len(samples)}ä¸ªæ ·æœ¬")

                meta_list = []
                h5_storage = HDF5Storage(self.cfg['data']['output_dir'])

                for idx, smp in enumerate(tqdm(samples, desc=f"  æ ·æœ¬", leave=False)):
                    result = self.process_single(smp, class_name)

                    if result is None:
                        continue

                    # å†™å…¥HDF5
                    h5_idx = h5_storage.append_single(
                        class_name,
                        result['image_pair'][0],
                        result['image_pair'][1],
                        result['mask']
                    )

                    # å‡†å¤‡å…ƒæ•°æ®
                    result['hdf5_index'] = h5_idx
                    del result['image_pair']  # å›¾åƒå·²ä¿å­˜åˆ°HDF5
                    meta_list.append(result)

                    # å®šæœŸæ¸…ç†å†…å­˜
                    if idx > 0 and idx % gc_every == 0:
                        gc.collect()
                        torch.cuda.empty_cache()

                # ä¿å­˜è¯¥ç±»åˆ«çš„å…ƒæ•°æ®
                if meta_list:
                    meta_file = meta_dir / f"{class_name}.json"
                    with open(meta_file, 'w', encoding='utf-8') as mf:
                        json.dump(meta_list, mf, indent=2, ensure_ascii=False, default=str)
                    all_meta_files.append(meta_file)

                    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
                    print(f"  âœ… å®Œæˆ: {len(meta_list)}ä¸ªæ ·æœ¬")
                    print(f"  ğŸ“Š å‚è€ƒç»„ä»¶å¹³å‡: {sum(len(m['reference_components']) for m in meta_list) / len(meta_list):.1f}")
                    print(f"  ğŸ“Š ç›®æ ‡ç»„ä»¶å¹³å‡: {sum(len(m['target_components']) for m in meta_list) / len(meta_list):.1f}")

                    # éªŒè¯å‡ ä¸ªæ ·æœ¬çš„åæ ‡
                    for i, meta in enumerate(meta_list[:3]):
                        ref_comps = meta['reference_components']
                        tar_comps = meta['target_components']
                        if ref_comps:
                            bbox = ref_comps[0]['bbox']
                            print(f"    æ ·æœ¬{i}å‚è€ƒç»„ä»¶åæ ‡: {bbox} (åº”åœ¨0-224èŒƒå›´å†…)")

                h5_storage.close()

            except Exception as e:
                print(f"âŒ å¤„ç†ç±»åˆ« {class_name} æ—¶å‡ºé”™: {e}")
                continue

        print(f"\nâœ… æ‰€æœ‰ç±»åˆ«å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(all_meta_files)} ä¸ªå…ƒæ•°æ®æ–‡ä»¶")
        return all_meta_files


# ---------- ç±»åˆ«æ„ŸçŸ¥çš„æ•°æ®åˆ’åˆ† ----------
class ClassAwareSplitter:
    def __init__(self, config):
        self.cfg = config

    def split_stream(self, meta_files):
        """æµå¼åˆ’åˆ†æ•°æ®é›†"""
        out_dir = Path(self.cfg['data']['output_dir'])
        out_dir.mkdir(parents=True, exist_ok=True)

        train_idx, val_idx, test_idx = [], [], []

        for mf in tqdm(meta_files, desc="åˆ’åˆ†æ•°æ®é›†"):
            cls = mf.stem
            try:
                with open(mf, 'r', encoding='utf-8') as f:
                    meta = json.load(f)

                if len(meta) < 3:
                    # æ ·æœ¬å¤ªå°‘ï¼Œå…¨éƒ¨æ”¾å…¥è®­ç»ƒé›†
                    train_idx.extend([{'class_name': cls, **m} for m in meta])
                    continue

                # åˆ’åˆ†æ•°æ®é›†
                tv, te = train_test_split(
                    meta,
                    test_size=self.cfg['data']['test_split'],
                    random_state=42
                )
                tr, va = train_test_split(
                    tv,
                    test_size=self.cfg['data']['val_split'] / (1 - self.cfg['data']['test_split']),
                    random_state=42
                )

                train_idx.extend(tr)
                val_idx.extend(va)
                test_idx.extend(te)

            except Exception as e:
                print(f"âŒ åˆ’åˆ†ç±»åˆ« {cls} æ—¶å‡ºé”™: {e}")
                continue

        # æ‰“ä¹±æ•°æ®
        random.shuffle(train_idx)
        random.shuffle(val_idx)
        random.shuffle(test_idx)

        # ä¿å­˜æœ€ç»ˆæ–‡ä»¶
        for name, lst in [('train', train_idx), ('val', val_idx), ('test', test_idx)]:
            output_file = out_dir / f"{name}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(lst, f, indent=2, ensure_ascii=False, default=str)
            print(f"âœ… {name}.json ä¿å­˜å®Œæˆï¼Œå…± {len(lst)} æ¡æ ·æœ¬")

            # éªŒè¯å‰å‡ ä¸ªæ ·æœ¬
            if lst:
                sample = lst[0]
                print(f"  ğŸ“‹ {name}é›†æ ·æœ¬ç¤ºä¾‹:")
                print(f"    ç±»åˆ«: {sample.get('class_name')}")
                print(f"    HDF5ç´¢å¼•: {sample.get('hdf5_index')}")
                print(f"    æ–‡æœ¬é•¿åº¦: {len(sample.get('differ_text', ''))}")
                if sample.get('reference_components'):
                    bbox = sample['reference_components'][0]['bbox']
                    print(f"    ç»„ä»¶åæ ‡ç¤ºä¾‹: {bbox}")


# ---------- ä¸»å…¥å£ ----------
def main():
    parser = ArgumentParser(description="GUIæ•°æ®é¢„å¤„ç†å·¥å…· - ä¿®å¤åæ ‡å¯¹é½é—®é¢˜")
    parser.add_argument('--debug', action='store_true', help="è°ƒè¯•æ¨¡å¼ï¼Œåªå¤„ç†å°‘é‡æ•°æ®")
    parser.add_argument('--gui_dir', type=str, help="GUIå›¾åƒç›®å½•è·¯å¾„")
    parser.add_argument('--text_dir', type=str, help="æ–‡æœ¬æè¿°ç›®å½•è·¯å¾„")
    parser.add_argument('--output_dir', type=str, help="è¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument('--validate_only', action='store_true', help="åªéªŒè¯ä¸å¤„ç†")

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    cfg = get_full_config()

    # è¦†ç›–é…ç½®ï¼ˆå¦‚æœæä¾›äº†å‘½ä»¤è¡Œå‚æ•°ï¼‰
    for k in ['gui_dir', 'text_dir', 'output_dir']:
        if getattr(args, k):
            cfg['data'][k] = getattr(args, k)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(cfg['data']['output_dir'])
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ¯ GUIæ•°æ®é¢„å¤„ç†å¼€å§‹")
    print(f"   å›¾åƒç›®å½•: {cfg['data']['gui_dir']}")
    print(f"   æ–‡æœ¬ç›®å½•: {cfg['data']['text_dir']}")
    print(f"   è¾“å‡ºç›®å½•: {cfg['data']['output_dir']}")
    print(f"   åŸå§‹å°ºå¯¸: {cfg['data']['original_size']}")
    print(f"   ç›®æ ‡å°ºå¯¸: {cfg['data']['image_size']}")
    print(f"   è°ƒè¯•æ¨¡å¼: {args.debug}")

    if args.validate_only:
        print("\nğŸ” éªŒè¯æ¨¡å¼ï¼šæ£€æŸ¥æ•°æ®å®Œæ•´æ€§")
        # è¿™é‡Œå¯ä»¥æ·»åŠ éªŒè¯ä»£ç 
        return

    # åˆ›å»ºé¢„å¤„ç†å™¨
    preprocessor = FixedGUIPreprocessor(cfg)

    # å¤„ç†æ‰€æœ‰æ•°æ®
    meta_files = preprocessor.process_all_stream(debug=args.debug)

    if not meta_files:
        print("âŒ æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å…ƒæ•°æ®æ–‡ä»¶")
        return

    # åˆ’åˆ†æ•°æ®é›†
    splitter = ClassAwareSplitter(cfg)
    splitter.split_stream(meta_files)

    print("\nğŸ‰ æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
    print(f"   è¾“å‡ºæ–‡ä»¶:")
    print(f"     - {output_dir}/images.h5 (å›¾åƒæ•°æ®)")
    print(f"     - {output_dir}/masks.h5 (maskæ•°æ®)")
    print(f"     - {output_dir}/train.json (è®­ç»ƒé›†)")
    print(f"     - {output_dir}/val.json (éªŒè¯é›†)")
    print(f"     - {output_dir}/test.json (æµ‹è¯•é›†)")
    print(f"     - {output_dir}/meta/*.json (å„ç±»åˆ«å…ƒæ•°æ®)")


if __name__ == "__main__":
    main()